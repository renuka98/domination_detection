{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Domination in Wikipedia\n",
    "Hypothesis: destructive domination where updates to a Wikipedia page are performed by relatively few users, at the (explicit) exclusion of other users by reverting their edits that were of good quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "\n",
    "#Preprocessing the logfile\n",
    "node_folder =  'wikidata/'\n",
    "timestamp_col='revtime'\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%dT%H:%M:%SZ') \n",
    "\n",
    "# read all the data into one data frame\n",
    "# remove all pages that have only single user edits\n",
    "nodefile = node_folder + 'benign_2013_' \n",
    "\n",
    "df_dev = pd.read_csv(nodefile + '1' + '.csv') #, parse_dates=['revtime'], date_parser=dateparse)\n",
    "df_dev['revtime'] = pd.to_datetime(df_dev['revtime'])\n",
    "df_complete = df_dev[df_dev.groupby(['pagetitle'])['username'].transform('nunique')>1]\n",
    "for i in range(2, 13):\n",
    "    df_temp = pd.read_csv(nodefile+ str(i) + '.csv')\n",
    "    df_temp['revtime'] = pd.to_datetime(df_temp['revtime'])\n",
    "    df = df_temp[df_temp.groupby(['pagetitle'])['username'].transform('nunique')>1]\n",
    "    df_complete = df_complete.append(df_temp)\n",
    "\n",
    "    \n",
    "nodefile = node_folder + 'benign_2014_' \n",
    "\n",
    "for i in range(1, 8):\n",
    "    df_temp = pd.read_csv(nodefile+ str(i) + '.csv')\n",
    "    df_temp['revtime'] = pd.to_datetime(df_temp['revtime'])\n",
    "    df = df_temp[df_temp.groupby(['pagetitle'],as_index=False)['username'].transform('nunique')>1]\n",
    "    df_complete = df_complete.append(df_temp)\n",
    "    \n",
    "df_complete.to_csv(node_folder + \"wiki_consolidated.csv\")\n",
    "df_complete\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "node_folder =  'wikidata/'\n",
    "timestamp_col='revtime'\n",
    "\n",
    "df_complete = pd.read_csv(node_folder + \"wiki_consolidated.csv\")\n",
    "df_complete['revtime'] = pd.to_datetime(df_complete['revtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.drop(['cluebotRevert', 'stiki_REP_USER'], axis=1)\n",
    "\n",
    "def get_reverted_user(group):\n",
    "    \n",
    "    group = group.sort_values('revtime', ascending=False, kind='mergesort')\n",
    "    \n",
    "    group['rev_username']=group['username'].shift(1)\n",
    "    group['rev_username']=group['rev_username'].fillna('NA')\n",
    "    \n",
    "    \n",
    "    return group\n",
    "\n",
    "\n",
    "#df_dev['userid'] = df_dev['userid'].fillna('NA')\n",
    "df_complete.index.name=None\n",
    "df_complete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_complete = df_complete.groupby('pagetitle', as_index=False).apply(get_reverted_user)\n",
    "print(df_complete.count())\n",
    "\n",
    "df_complete.index.name=None\n",
    "df_complete.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_complete.to_csv(node_folder + \"wiki_processed_rev.csv\")\n",
    "\n",
    "df_total_users =  df_complete.groupby('pagetitle')['username'].agg(['nunique'])\n",
    "print(df_total_users.count())\n",
    "df_total_users.reset_index(inplace=True)\n",
    "df_complete.reset_index(inplace=True,drop=True)\n",
    "\n",
    "df_true = df_complete[df_complete.isReverted==True]\n",
    "df_true= df_true[df_true['username']!=df_true['rev_username']]\n",
    "\n",
    "#print(df_true)\n",
    "df_true.index.name=None\n",
    "df_true.reset_index(inplace=True, drop=True)\n",
    "df_true = df_true.sort_values(['revtime'], ascending=True, kind='mergesort')\n",
    "page_list = list(df_true.pagetitle.unique())\n",
    "#print(page_list)\n",
    "\n",
    "df_true.to_csv(node_folder + \"wiki_revertdata.csv\")\n",
    "df_min_max_score = df_true.groupby('pagetitle')['stiki_score'].agg(['mean', 'count', 'median'])\n",
    "\n",
    "df_nusers =  df_true.groupby('pagetitle')['username'].agg(['nunique'])\n",
    "\n",
    "df_min_max_score = df_min_max_score.merge(df_nusers, on='pagetitle', how='left')\n",
    "#print(df_min_max_score)\n",
    "df_min_max_score = df_min_max_score.sort_values(['nunique'], ascending=False, kind='mergesort')\n",
    "df_min_max_score.reset_index(inplace=True)\n",
    "df_min_max_score= df_min_max_score[~df_min_max_score['pagetitle'].str.contains(\"Wikipedia\")]\n",
    "df_min_max_score = df_min_max_score.iloc[3:]\n",
    "df_min_max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false = df_complete[df_complete.isReverted==False]\n",
    "df_false = df_false[df_false.pagetitle.isin(page_list)]\n",
    "print(df_false)\n",
    "df_false.to_csv(node_folder + \"wiki_non_revertdata.csv\")\n",
    "df_false.index.name=None\n",
    "df_false.reset_index(inplace=True, drop=True)\n",
    "df_false = df_false.sort_values(['revtime'], ascending=True, kind='mergesort')\n",
    "df_min_max_fscore = df_false.groupby('pagetitle')['stiki_score'].agg(['mean', 'max', 'count', 'median'])\n",
    "#print(df_min_max_fscore)\n",
    "df_nfusers =  df_false.groupby('pagetitle')['username'].agg(['nunique'])\n",
    "\n",
    "df_min_max_fscore = df_min_max_fscore.merge(df_nfusers, on='pagetitle', how='left')\n",
    "\n",
    "df_min_max_fscore = df_min_max_fscore.sort_values(['nunique'], ascending=False, kind='mergesort')\n",
    "df_min_max_fscore.reset_index(inplace=True)\n",
    "df_min_max_fscore= df_min_max_fscore[~df_min_max_fscore['pagetitle'].str.contains(\"Wikipedia\")]\n",
    "df_min_max_fscore.rename(columns={'mean':'no_revert_mean', 'max':'no_revert_max', 'count':'no_revert_count', 'median':'no_revert_median', 'nunique':'no_revert_users'}, inplace=True)\n",
    "\n",
    "df_min_max_score.rename(columns={'mean':'revert_mean', 'max':'revert_median', 'count':'revert_count','nunique':'revert_users'}, inplace=True)\n",
    "\n",
    "df_min_max_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ncomplete = df_false.append(df_true)\n",
    "df_total_rscore = df_ncomplete.groupby('pagetitle')['stiki_score'].agg(['median'])\n",
    "\n",
    "\n",
    "df_final = df_min_max_score.merge(df_min_max_fscore, on='pagetitle', how='left')\n",
    "df_final = df_final.merge(df_total_rscore, on='pagetitle', how='right')\n",
    "df_final = df_final.merge(df_total_users, on='pagetitle', how='right')\n",
    "\n",
    "df_final.dropna(inplace=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(node_folder + \"wiki_domination_h1_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
